<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b3cb38518cf4fe7714d2f5e74dfa3eb",
  "translation_date": "2025-10-03T10:23:33+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "bg"
}
-->
# Основи на инженерството на подсказки

[![Основи на инженерството на подсказки](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.bg.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Въведение
Този модул обхваща основни концепции и техники за създаване на ефективни подсказки за генеративни AI модели. Начинът, по който пишете вашата подсказка към LLM, също има значение. Внимателно създадената подсказка може да постигне по-добро качество на отговора. Но какво точно означават термини като _подсказка_ и _инженерство на подсказки_? И как да подобря входа на подсказката, който изпращам към LLM? Това са въпросите, на които ще се опитаме да отговорим в тази глава и следващата.

_Генеративният AI_ е способен да създава ново съдържание (например текст, изображения, аудио, код и др.) в отговор на потребителски заявки. Това се постига чрез _Големи езикови модели_ като серията GPT ("Generative Pre-trained Transformer") на OpenAI, които са обучени да използват естествен език и код.

Потребителите вече могат да взаимодействат с тези модели чрез познати парадигми като чат, без да се нуждаят от техническа експертиза или обучение. Моделите са _базирани на подсказки_ - потребителите изпращат текстов вход (подсказка) и получават обратно отговор от AI (завършване). След това те могат "да разговарят с AI" многократно, в многопосочни разговори, като усъвършенстват подсказката си, докато отговорът съответства на техните очаквания.

"Подсказките" сега се превръщат в основния _програмен интерфейс_ за приложенията на генеративния AI, като казват на моделите какво да правят и влияят върху качеството на върнатите отговори. "Инженерството на подсказки" е бързо развиваща се област на изследване, която се фокусира върху _проектирането и оптимизацията_ на подсказки за постигане на последователни и качествени отговори в мащаб.

## Цели на обучението

В този урок ще научим какво е инженерство на подсказки, защо е важно и как можем да създаваме по-ефективни подсказки за даден модел и цел на приложението. Ще разберем основни концепции и добри практики за инженерство на подсказки - и ще научим за интерактивна среда "пясъчник" в Jupyter Notebooks, където можем да видим тези концепции приложени към реални примери.

До края на този урок ще можем:

1. Да обясним какво е инженерство на подсказки и защо е важно.
2. Да опишем компонентите на подсказката и как се използват.
3. Да научим добри практики и техники за инженерство на подсказки.
4. Да приложим научените техники към реални примери, използвайки OpenAI endpoint.

## Основни термини

Инженерство на подсказки: Практиката на проектиране и усъвършенстване на входове за насочване на AI модели към създаване на желани изходи.
Токенизация: Процесът на преобразуване на текст в по-малки единици, наречени токени, които моделът може да разбере и обработи.
LLM, настроени за инструкции: Големи езикови модели (LLMs), които са фино настроени със специфични инструкции за подобряване на точността и релевантността на отговорите.

## Пясъчник за обучение

Инженерството на подсказки в момента е повече изкуство, отколкото наука. Най-добрият начин да подобрим интуицията си за него е да _практикуваме повече_ и да възприемем подход на проба и грешка, който комбинира експертиза в приложната област с препоръчани техники и оптимизации, специфични за модела.

Jupyter Notebook, който съпровожда този урок, предоставя среда _пясъчник_, където можете да изпробвате наученото - докато напредвате или като част от предизвикателството с код в края. За да изпълните упражненията, ще ви трябват:

1. **Ключ за Azure OpenAI API** - крайна точка на услугата за разположен LLM.
2. **Python Runtime** - в който Notebook може да бъде изпълнен.
3. **Локални променливи на средата** - _завършете [НАСТРОЙКАТА](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) сега, за да се подготвите_.

Notebook идва с _начални_ упражнения - но се насърчавате да добавите свои собствени _Markdown_ (описание) и _Code_ (заявки за подсказки) секции, за да изпробвате повече примери или идеи - и да изградите интуицията си за проектиране на подсказки.

## Илюстрирано ръководство

Искате ли да получите обща представа за това, което обхваща този урок, преди да се потопите? Разгледайте това илюстрирано ръководство, което ви дава представа за основните теми, обхванати в урока, и ключовите изводи, върху които да помислите за всяка от тях. Пътната карта на урока ви води от разбирането на основните концепции и предизвикателства до тяхното адресиране с подходящи техники и добри практики за инженерство на подсказки. Обърнете внимание, че секцията "Напреднали техники" в това ръководство се отнася до съдържание, обхванато в _следващата_ глава на тази учебна програма.

![Илюстрирано ръководство за инженерство на подсказки](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.bg.png)

## Нашият стартъп

Сега, нека поговорим за това как _тази тема_ се отнася до нашата мисия за стартъп да [внесе AI иновации в образованието](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Искаме да изградим AI-задвижвани приложения за _персонализирано обучение_ - така че нека помислим как различни потребители на нашето приложение могат да "проектират" подсказки:

- **Администратори** могат да помолят AI да _анализира данни за учебната програма, за да идентифицира пропуски в покритието_. AI може да обобщи резултатите или да ги визуализира с код.
- **Преподаватели** могат да помолят AI да _генерира учебен план за целева аудитория и тема_. AI може да създаде персонализиран план в определен формат.
- **Ученици** могат да помолят AI да _ги обучава по труден предмет_. AI може да насочва учениците с уроци, подсказки и примери, съобразени с тяхното ниво.

Това е само върхът на айсберга. Разгледайте [Подсказки за образование](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - библиотека с отворен код за подсказки, курирана от образователни експерти - за да получите по-широка представа за възможностите! _Опитайте да изпълните някои от тези подсказки в пясъчника или използвайте OpenAI Playground, за да видите какво ще се случи!_

<!--
ШАБЛОН НА УРОКА:
Тази единица трябва да обхваща основна концепция #1.
Укрепете концепцията с примери и препратки.

КОНЦЕПЦИЯ #1:
Инженерство на подсказки.
Определете го и обяснете защо е необходимо.
-->

## Какво е инженерство на подсказки?

Започнахме този урок, като дефинирахме **Инженерство на подсказки** като процес на _проектиране и оптимизация_ на текстови входове (подсказки) за постигане на последователни и качествени отговори (завършвания) за дадена цел на приложението и модел. Можем да мислим за това като за двустепенен процес:

- _проектиране_ на първоначалната подсказка за даден модел и цел
- _усъвършенстване_ на подсказката многократно, за да се подобри качеството на отговора

Това е задължително процес на проба и грешка, който изисква интуиция и усилия от страна на потребителя, за да се постигнат оптимални резултати. Но защо е важно? За да отговорим на този въпрос, първо трябва да разберем три концепции:

- _Токенизация_ = как моделът "вижда" подсказката
- _Основни LLM_ = как основният модел "обработва" подсказката
- _LLM, настроени за инструкции_ = как моделът вече може да вижда "задачи"

### Токенизация

LLM вижда подсказките като _последователност от токени_, където различни модели (или версии на модел) могат да токенизират една и съща подсказка по различни начини. Тъй като LLMs са обучени на токени (а не на суров текст), начинът, по който подсказките се токенизират, има пряко въздействие върху качеството на генерирания отговор.

За да получите интуиция за това как работи токенизацията, опитайте инструменти като [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst), показан по-долу. Копирайте вашата подсказка - и вижте как тя се преобразува в токени, като обърнете внимание на начина, по който се обработват символите за интервали и пунктуационните знаци. Обърнете внимание, че този пример показва по-стар LLM (GPT-3) - така че опитът с по-нов модел може да произведе различен резултат.

![Токенизация](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.bg.png)

### Концепция: Основни модели

След като подсказката е токенизирана, основната функция на ["Основния LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (или Основния модел) е да предскаже следващия токен в тази последователност. Тъй като LLMs са обучени на огромни текстови набори от данни, те имат добро усещане за статистическите връзки между токените и могат да направят тази прогноза с известна увереност. Обърнете внимание, че те не разбират _значението_ на думите в подсказката или токена; те просто виждат модел, който могат да "завършат" със следващата си прогноза. Те могат да продължат да предсказват последователността, докато не бъдат прекратени от потребителя или от някакво предварително установено условие.

Искате ли да видите как работи завършването, базирано на подсказки? Въведете горната подсказка в [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) на Azure OpenAI Studio с настройките по подразбиране. Системата е конфигурирана да третира подсказките като заявки за информация - така че трябва да видите завършване, което удовлетворява този контекст.

Но какво, ако потребителят иска да види нещо конкретно, което отговаря на някакви критерии или цел на задачата? Тук влизат в действие _LLM, настроени за инструкции_.

![Завършване на чат с основен LLM](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.bg.png)

### Концепция: LLM, настроени за инструкции

[LLM, настроен за инструкции](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) започва с основния модел и го фино настройва с примери или двойки вход/изход (например многопосочни "съобщения"), които могат да съдържат ясни инструкции - и отговорът от AI се опитва да следва тази инструкция.

Това използва техники като Укрепващо обучение с обратна връзка от хора (RLHF), които могат да обучат модела да _следва инструкции_ и _да се учи от обратна връзка_, така че да произвежда отговори, които са по-подходящи за практически приложения и по-релевантни за целите на потребителя.

Нека го изпробваме - върнете се към горната подсказка, но сега променете _системното съобщение_, за да предоставите следната инструкция като контекст:

> _Обобщете съдържанието, което ви е предоставено, за ученик от втори клас. Ограничете резултата до един параграф с 3-5 точки._

Вижте как резултатът сега е настроен да отразява желаната цел и формат? Преподавателят вече може директно да използва този отговор в своите слайдове за този клас.

![Завършване на чат с LLM, настроен за инструкции](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.bg.png)

## Защо ни е нужно инженерство на подсказки?

Сега, когато знаем как подсказките се обработват от LLMs, нека поговорим за _защо_ ни е нужно инженерство на подсказки. Отговорът се крие във факта, че текущите LLMs поставят редица предизвикателства, които правят _надеждните и последователни завършвания_ по-трудни за постигане, без да се полагат усилия за конструиране и оптимизация на подсказките. Например:

1. **Отговорите на модела са стохастични.** _Една и съща подсказка_ вероятно ще произведе различни отговори с различни модели или версии на модела. И може дори да произведе различни резултати със _същия модел_ в различни моменти. _Техниките за инженерство на подсказки могат да ни помогнат да минимизираме тези вариации, като предоставим по-добри насоки_.

1. **Моделите могат да фабрикуват отговори.** Моделите са предварително обучени с _големи, но ограничени_ набори от данни, което означава, че им липсва знание за концепции извън този обхват на обучение. В резултат на това те могат да произведат завършвания, които са неточни, въображаеми или директно противоречащи на известни факти. _Техниките за инженерство на подсказки помагат на потребителите да идентифицират и смекчат такива фабрикации, например, като поискат от AI цитати или разсъждения_.

1. **Способностите на моделите ще варират.** По-новите модели или поколения модели ще имат по-богати способности, но също така ще донесат уникални особености и компромиси в разходите и сложността. _Инженерството на подсказки може да ни помогне да разработим добри практики и работни потоци, които абстрахират разликите и се адаптират към специфичните изисквания на модела по мащабируем и безпроблемен начин_.

Нека видим това в действие в OpenAI или Azure OpenAI Playground:

- Използвайте една и съща подсказка с различни LLM разположения (например OpenAI, Azure OpenAI, Hugging Face) - видяхте ли вариациите?
- Използвайте една и съща подсказка многократно със _същото_ LLM разположение (например Azure OpenAI Playground) - как се различаваха тези вариации?

### Пример за фабрикации

В този курс използваме термина **"фабрикация"**, за да се позовем на явлението, при което LLMs понякога генерират фактически нет
Едно уеб търсене ми показа, че има измислени разкази (например телевизионни сериали или книги) за войни на Марс – но нито един от тях не се случва през 2076 г. Логиката също ни подсказва, че 2076 г. е _в бъдещето_ и следователно не може да бъде свързана с реално събитие.

Какво се случва, когато използваме този въпрос с различни доставчици на LLM?

> **Отговор 1**: OpenAI Playground (GPT-35)

![Отговор 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.bg.png)

> **Отговор 2**: Azure OpenAI Playground (GPT-35)

![Отговор 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.bg.png)

> **Отговор 3**: Hugging Face Chat Playground (LLama-2)

![Отговор 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.bg.png)

Както се очакваше, всяка моделна версия генерира леко различни отговори благодарение на стохастичното поведение и вариациите в способностите на модела. Например, един модел се насочва към аудитория от осми клас, докато друг предполага ученици от гимназията. Но и трите модела генерираха отговори, които биха могли да убедят неинформиран потребител, че събитието е реално.

Техники за инженеринг на въпроси като _метапромптинг_ и _конфигурация на температурата_ могат да намалят измислиците на модела до известна степен. Нови архитектури за инженеринг на въпроси също интегрират нови инструменти и техники безпроблемно в потока на въпросите, за да смекчат или намалят някои от тези ефекти.

## Казус: GitHub Copilot

Нека завършим този раздел, като разгледаме как инженерингът на въпроси се използва в реални решения, като разгледаме един казус: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot е вашият "AI партньор програмист" – той преобразува текстови въпроси в предложения за код и е интегриран във вашата среда за разработка (например Visual Studio Code) за безпроблемно потребителско изживяване. Както е документирано в поредица от блогове по-долу, най-ранната версия се основаваше на модела OpenAI Codex – като инженерите бързо осъзнаха необходимостта от фина настройка на модела и разработване на по-добри техники за инженеринг на въпроси, за да подобрят качеството на кода. През юли те [представиха подобрен AI модел, който надхвърля Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) за още по-бързи предложения.

Прочетете публикациите в ред, за да проследите тяхното обучение.

- **Май 2023** | [GitHub Copilot става по-добър в разбирането на вашия код](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Май 2023** | [В GitHub: Работа с LLM-овете зад GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Юни 2023** | [Как да пишете по-добри въпроси за GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Юли 2023** | [.. GitHub Copilot надхвърля Codex с подобрен AI модел](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Юли 2023** | [Ръководство за разработчици за инженеринг на въпроси и LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Септември 2023** | [Как да изградите корпоративно приложение с LLM: Уроци от GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Можете също да разгледате техния [инженерен блог](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) за повече публикации като [тази](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), която показва как тези модели и техники се _прилагат_ за задвижване на реални приложения.

---

## Конструкция на въпроси

Видяхме защо инженерингът на въпроси е важен – сега нека разберем как въпросите се _конструират_, за да можем да оценим различни техники за по-ефективен дизайн на въпроси.

### Основен въпрос

Нека започнем с основния въпрос: текстов вход, изпратен към модела без допълнителен контекст. Ето пример – когато изпратим първите няколко думи от националния химн на САЩ към OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), той незабавно _завършва_ отговора с следващите редове, илюстрирайки основното предсказателно поведение.

| Въпрос (Вход)     | Завършване (Изход)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Изглежда, че започвате текста на "The Star-Spangled Banner", националния химн на Съединените щати. Пълният текст е ...                     |

### Сложен въпрос

Сега нека добавим контекст и инструкции към този основен въпрос. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) ни позволява да конструираме сложен въпрос като колекция от _съобщения_ с:

- Вход/изход двойки, отразяващи _потребителски_ вход и _асистентски_ отговор.
- Системно съобщение, задаващо контекста за поведението или личността на асистента.

Заявката вече е във формата по-долу, където _токенизацията_ ефективно улавя релевантна информация от контекста и разговора. Сега промяната на системния контекст може да бъде толкова въздействаща върху качеството на завършванията, колкото предоставените потребителски входове.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```


### Инструкционен въпрос

В горните примери потребителският въпрос беше прост текстов запитване, което може да се интерпретира като искане за информация. С _инструкционни_ въпроси можем да използваме този текст, за да уточним задача в повече детайли, предоставяйки по-добри насоки на AI. Ето пример:

| Въпрос (Вход)                                                                                                                                                                                                                         | Завършване (Изход)                                                                                                        | Тип инструкция      |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Напишете описание на Гражданската война                                                                                                                                                                                                | _върнат е прост параграф_                                                                                                 | Прост               |
| Напишете описание на Гражданската война. Посочете ключови дати и събития и опишете тяхното значение                                                                                                                                    | _върнат е параграф, последван от списък с ключови дати на събития с описания_                                             | Сложен              |
| Напишете описание на Гражданската война в 1 параграф. Посочете 3 ключови дати и тяхното значение. Посочете още 3 ключови исторически фигури и техните приноси. Върнете изхода като JSON файл.                                           | _върнат е по-обширен текст, форматиран като JSON, който можете да копирате и поставите в файл и да го валидирате при нужда_ | Сложен. Форматиран. |

## Основно съдържание

В горните примери въпросът все още беше доста отворен, позволявайки на LLM да реши коя част от предварително обучената си база данни е релевантна. С дизайна на _основно съдържание_, входният текст се разделя на две части:

- инструкция (действие)
- релевантно съдържание (което влияе на действието)

Ето пример, където инструкцията е "обобщете това в 2 изречения".

| Въпрос (Вход)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Завършване (Изход)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от тази на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с невъоръжено око в нощното небе, и е известен на древните цивилизации още преди записаната история. Той е наречен на римския бог Юпитер. Когато се наблюдава от Земята, Юпитер може да бъде достатъчно ярък, за да хвърля видими сенки, и е средно третият най-ярък естествен обект в нощното небе след Луната и Венера. <br/> **Обобщете това в 2 кратки изречения** | Юпитер, петата планета от Слънцето, е най-голямата в Слънчевата система и е известен като един от най-ярките обекти в нощното небе. Наречен на римския бог Юпитер, той е газов гигант с маса, два и половина пъти по-голяма от тази на всички останали планети в Слънчевата система. |

Сегментът с основно съдържание може да се използва по различни начини за по-ефективни инструкции:

- **Примери** – вместо да казвате на модела какво да прави с явна инструкция, дайте му примери за това какво да прави и го оставете да извлече модела.
- **Подсказки** – следвайте инструкцията с "подсказка", която насочва завършването, насочвайки модела към по-релевантни отговори.
- **Шаблони** – това са повторяеми "рецепти" за въпроси с плейсхолдъри (променливи), които могат да бъдат персонализирани с данни за конкретни случаи.

Нека разгледаме тези техники в действие.

### Използване на примери

Това е подход, при който използвате основното съдържание, за да "подадете на модела" някои примери за желания изход за дадена инструкция и го оставяте да извлече модела за желания изход. В зависимост от броя на предоставените примери можем да имаме въпроси с нулеви примери, единични примери, няколко примера и т.н.

Въпросът сега се състои от три компонента:

- Описание на задачата
- Няколко примера за желания изход
- Началото на нов пример (което става имплицитно описание на задачата)

| Тип обучение | Въпрос (Вход)                                                                                                                                        | Завършване (Изход)         |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------- |
| Нулеви примери | "Слънцето грее". Преведете на испански                                                                                                              | "El Sol está brillando".   |
| Единичен пример | "Слънцето грее" => ""El Sol está brillando". <br> "Денят е студен и ветровит" =>                                                                   | "Es un día frío y ventoso". |
| Няколко примера | Играчът пробяга базите => Бейзбол <br/> Играчът удари ас => Тенис <br/> Играчът удари шест => Крикет <br/> Играчът направи забивка =>              | Баскетбол                  |
|               |                                                                                                                                                       |                             |

Забележете как трябваше да предоставим явна инструкция ("Преведете на испански") при въпрос с нулеви примери, но тя се извежда при въпроса с единичен пример. Примерът с няколко примера показва как добавянето на повече примери позволява на моделите да правят по-точни изводи без допълнителни инструкции.

### Подсказки във въпроса

Друга техника за използване на основно съдържание е предоставянето на _подсказки_, а не примери. В този случай даваме на модела насока в правилната посока, като _започваме_ с откъс, който отразява желания формат на отговора. Моделът след това "взема подсказката", за да продължи в същия дух.

| Брой подсказки | Въпрос (Вход)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Завършване (Изход)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от тази на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с невъоръжено око в нощното небе, и е известен на древните цивилизации още преди записаната история. <br/>**Обобщете това**                                       | Юпитер е най-голямата планета в нашата Слънчева система и петата от Слънцето. Той е газов гигант с маса, равна на 1/1000 от тази на Слънцето, но е по-тежък от всички останали планети, взети заедно. Древните цивилизации са знаели за Юпитер отдавна, и той е лесно видим в нощното небе. |
| 1              | Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от масата на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с невъоръжено око в нощното небе, и е бил известен на древните цивилизации още преди записаната история. <br/>**Обобщете това** <br/> Научихме, че Юпитер | е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от масата на всички останали планети, взети заедно. Лесно се вижда с невъоръжено око и е известен още от древни времена.                        |
| 2              | Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от масата на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с невъоръжено око в нощното небе, и е бил известен на древните цивилизации още преди записаната история. <br/>**Обобщете това** <br/> Топ 3 факта, които научихме:         | 1. Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. <br/> 2. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето...<br/> 3. Юпитер е видим с невъоръжено око още от древни времена ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Шаблони за подсказки

Шаблонът за подсказка е _предварително дефинирана рецепта за подсказка_, която може да се съхранява и използва повторно при необходимост, за да се осигури по-последователно потребителско изживяване в мащаб. В най-простата си форма това е просто колекция от примери за подсказки като [този от OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), който предоставя както интерактивните компоненти на подсказката (съобщения от потребителя и системата), така и формата на заявката, управлявана от API - за поддръжка на повторна употреба.

В по-сложната си форма, като [този пример от LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), той съдържа _заместители_, които могат да бъдат заменени с данни от различни източници (потребителски вход, системен контекст, външни източници на данни и др.), за да се генерира подсказка динамично. Това ни позволява да създадем библиотека от повторно използваеми подсказки, които могат да се използват за осигуряване на последователно потребителско изживяване **програмно** в мащаб.

Накрая, истинската стойност на шаблоните се крие в способността да се създават и публикуват _библиотеки с подсказки_ за вертикални приложни области, където шаблонът за подсказка вече е _оптимизиран_, за да отразява специфичен за приложението контекст или примери, които правят отговорите по-релевантни и точни за целевата аудитория. Репозиторият [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) е чудесен пример за този подход, като събира библиотека от подсказки за образователната област с акцент върху ключови цели като планиране на уроци, дизайн на учебни програми, обучение на ученици и др.

## Поддържащо съдържание

Ако разглеждаме създаването на подсказки като съставено от инструкция (задача) и цел (основно съдържание), тогава _вторичното съдържание_ е като допълнителен контекст, който предоставяме, за да **влияем на изхода по някакъв начин**. Това може да бъдат параметри за настройка, инструкции за форматиране, таксономии на теми и др., които могат да помогнат на модела да _адаптира_ отговора си, за да отговаря на желаните цели или очаквания на потребителя.

Например: Като се има предвид каталог на курсове с обширни метаданни (име, описание, ниво, метаданни, инструктор и др.) за всички налични курсове в учебната програма:

- можем да дефинираме инструкция за "обобщаване на каталога на курсовете за есента на 2023 г."
- можем да използваме основното съдържание, за да предоставим няколко примера за желания изход
- можем да използваме вторичното съдържание, за да идентифицираме топ 5 "етикета" от интерес.

Сега моделът може да предостави обобщение във формата, показан от няколко примера - но ако резултатът има множество етикети, той може да приоритизира 5-те етикета, идентифицирани във вторичното съдържание.

---

<!--
Шаблон за урок:
Тази единица трябва да обхваща основна концепция #1.
Подсилете концепцията с примери и препратки.

КОНЦЕПЦИЯ #3:
Техники за инженеринг на подсказки.
Какви са някои основни техники за инженеринг на подсказки?
Илюстрирайте ги с упражнения.
-->

## Най-добри практики за подсказване

Сега, когато знаем как подсказките могат да бъдат _конструирани_, можем да започнем да мислим за това как да ги _проектираме_, за да отразяват най-добрите практики. Можем да мислим за това в две части - да имаме правилната _нагласа_ и да прилагаме правилните _техники_.

### Нагласа за инженеринг на подсказки

Инженерингът на подсказки е процес на проби и грешки, така че имайте предвид три широки водещи фактора:

1. **Разбирането на домейна има значение.** Точността и релевантността на отговора са функция на _домейна_, в който работи приложението или потребителят. Използвайте интуицията и експертния си опит в домейна, за да **персонализирате техниките** допълнително. Например, дефинирайте _домейн-специфични личности_ в системните си подсказки или използвайте _домейн-специфични шаблони_ в потребителските си подсказки. Осигурете вторично съдържание, което отразява домейн-специфични контексти, или използвайте _домейн-специфични сигнали и примери_, за да насочите модела към познати модели на употреба.

2. **Разбирането на модела има значение.** Знаем, че моделите са стохастични по природа. Но имплементациите на моделите могат също да варират по отношение на набора от данни за обучение, който използват (предварително обучени знания), способностите, които предоставят (например чрез API или SDK), и типа съдържание, за което са оптимизирани (например код срещу изображения срещу текст). Разберете силните и слабите страни на модела, който използвате, и използвайте тези знания, за да _приоритизирате задачи_ или да изградите _персонализирани шаблони_, които са оптимизирани за способностите на модела.

3. **Итерацията и валидирането имат значение.** Моделите се развиват бързо, както и техниките за инженеринг на подсказки. Като експерт в домейна, може да имате друг контекст или критерии за _вашето_ специфично приложение, които може да не се прилагат за по-широката общност. Използвайте инструменти и техники за инженеринг на подсказки, за да "започнете" създаването на подсказки, след това итерирайте и валидирайте резултатите, използвайки собствената си интуиция и експертен опит в домейна. Запишете своите прозрения и създайте **база знания** (например библиотеки с подсказки), които могат да се използват като нова основа от други за по-бързи итерации в бъдеще.

## Най-добри практики

Сега нека разгледаме общите най-добри практики, препоръчани от [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) и практикуващи от [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Какво                              | Защо                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Оценявайте най-новите модели.       | Новите поколения модели вероятно ще имат подобрени функции и качество - но може също да доведат до по-високи разходи. Оценете ги за въздействие, след това вземете решения за миграция.                                                                                |
| Разделяйте инструкции и контекст   | Проверете дали вашият модел/доставчик дефинира _разделители_, за да разграничи инструкциите, основното и вторичното съдържание по-ясно. Това може да помогне на моделите да присвояват тежести по-точно на токените.                                                         |
| Бъдете конкретни и ясни             | Дайте повече подробности за желания контекст, резултат, дължина, формат, стил и др. Това ще подобри както качеството, така и последователността на отговорите. Запишете рецепти в повторно използваеми шаблони.                                                          |
| Бъдете описателни, използвайте примери      | Моделите може да реагират по-добре на подхода "покажи и разкажи". Започнете с подхода `zero-shot`, където давате инструкция (но без примери), след това опитайте `few-shot` като усъвършенстване, предоставяйки няколко примера за желания изход. Използвайте аналогии. |
| Използвайте сигнали за стартиране на завършвания | Насочете го към желания резултат, като му дадете някои водещи думи или фрази, които може да използва като начална точка за отговора.                                                                                                               |
| Повторете                       | Понякога може да се наложи да повторите себе си пред модела. Дайте инструкции преди и след основното съдържание, използвайте инструкция и сигнал и т.н. Итерирайте и валидирайте, за да видите какво работи.                                                         |
| Редът има значение                     | Редът, в който представяте информацията на модела, може да повлияе на изхода, дори в учебните примери, благодарение на пристрастие към последователността. Опитайте различни опции, за да видите какво работи най-добре.                                                               |
| Дайте на модела "изход"           | Дайте на модела _резервен_ отговор, който може да предостави, ако не може да изпълни задачата по някаква причина. Това може да намали шансовете моделите да генерират неверни или измислени отговори.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Както при всяка най-добра практика, помнете, че _вашият опит може да варира_ в зависимост от модела, задачата и домейна. Използвайте тези като отправна точка и итерирайте, за да намерите какво работи най-добре за вас. Постоянно преоценявайте процеса си за инженеринг на подсказки, когато се появяват нови модели и инструменти, с акцент върху мащабируемостта на процеса и качеството на отговорите.

<!--
Шаблон за урок:
Тази единица трябва да предостави предизвикателство с код, ако е приложимо

ПРЕДИЗВИКАТЕЛСТВО:
Връзка към Jupyter Notebook с инструкции само в коментарите на кода (секциите с код са празни).

РЕШЕНИЕ:
Връзка към копие на този Notebook с попълнени и изпълнени подсказки, показващо какво може да бъде един пример.
-->

## Задание

Поздравления! Стигнахте до края на урока! Време е да приложите някои от тези концепции и техники на практика с реални примери!

За нашето задание ще използваме Jupyter Notebook с упражнения, които можете да изпълните интерактивно. Можете също така да разширите Notebook с ваши собствени Markdown и Code клетки, за да изследвате идеи и техники самостоятелно.

### За да започнете, направете fork на репозитория, след това

- (Препоръчително) Стартирайте GitHub Codespaces
- (Алтернативно) Клонирайте репозитория на вашето локално устройство и го използвайте с Docker Desktop
- (Алтернативно) Отворете Notebook с предпочитаната от вас среда за изпълнение на Notebook.

### След това конфигурирайте вашите променливи на средата

- Копирайте файла `.env.copy` в корена на репозитория в `.env` и попълнете стойностите `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` и `AZURE_OPENAI_DEPLOYMENT`. Върнете се към [секцията Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), за да научите как.

### След това отворете Jupyter Notebook

- Изберете ядрото за изпълнение. Ако използвате опции 1 или 2, просто изберете ядрото Python 3.10.x, предоставено от контейнера за разработка.

Вие сте готови да изпълните упражненията. Имайте предвид, че тук няма _правилни и грешни_ отговори - просто изследвате опции чрез проби и грешки и изграждате интуиция за това какво работи за даден модел и приложен домейн.

_Поради тази причина няма сегменти с решения на код в този урок. Вместо това Notebook ще има Markdown клетки, озаглавени "Моето решение:", които показват един примерен изход за справка._

 <!--
Шаблон за урок:
Обобщете секцията с резюме и ресурси за самостоятелно обучение.
-->

## Проверка на знанията

Кое от следните е добра подсказка, следваща някои разумни най-добри практики?

1. Покажи ми изображение на червена кола
2. Покажи ми изображение на червена кола от марка Volvo и модел XC90, паркирана до скала с залязващо слънце
3. Покажи ми изображение на червена кола от марка Volvo и модел XC90

О: 2, това е най-добрата подсказка, тъй като предоставя подробности за "какво" и навлиза в конкретика (не просто всяка кола, а конкретна марка и модел), а също така описва общата обстановка. 3 е следващата най-добра, тъй като също съдържа много описание.

## 🚀 Предизвикателство

Опитайте да използвате техниката "сигнал" с подсказката: Завършете изречението "Покажи ми изображение на червена кола от марка Volvo и ". Какво отговаря, и как бихте го подобрили?

## Чудесна работа! Продължете обучението си

Искате да научите повече за различни концепции за инженеринг на подсказки? Отидете на [страницата за продължаващо обучение](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да намерите други страхотни ресурси по тази тема.

Преминете към Урок 5, където ще разгледаме [усъвършенствани техники за подсказване](../

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.