<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b3cb38518cf4fe7714d2f5e74dfa3eb",
  "translation_date": "2025-10-03T08:15:08+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "ru"
}
-->
# Основы проектирования запросов

[![Основы проектирования запросов](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.ru.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Введение
Этот модуль охватывает ключевые концепции и техники создания эффективных запросов для генеративных моделей ИИ. То, как вы формулируете свой запрос для LLM, имеет значение. Тщательно составленный запрос может обеспечить более качественный ответ. Но что именно означают такие термины, как _запрос_ и _проектирование запросов_? И как улучшить _входной запрос_, который вы отправляете в LLM? На эти вопросы мы постараемся ответить в этой главе и следующей.

_Генеративный ИИ_ способен создавать новый контент (например, текст, изображения, аудио, код и т.д.) в ответ на запросы пользователей. Это достигается с помощью _Больших языковых моделей_ (LLM), таких как серия GPT ("Generative Pre-trained Transformer") от OpenAI, которые обучены работать с естественным языком и кодом.

Теперь пользователи могут взаимодействовать с этими моделями через привычные интерфейсы, такие как чат, без необходимости технической подготовки или обучения. Модели основаны на _запросах_ — пользователи отправляют текстовый запрос и получают ответ от ИИ (завершение). Затем они могут "общаться с ИИ" итеративно, в многократных диалогах, уточняя запрос, пока ответ не будет соответствовать их ожиданиям.

"Запросы" становятся основным _программным интерфейсом_ для приложений генеративного ИИ, определяя, что модели должны делать, и влияя на качество возвращаемых ответов. "Проектирование запросов" — это быстро развивающаяся область, которая сосредоточена на _разработке и оптимизации_ запросов для обеспечения стабильных и качественных ответов в масштабах.

## Цели обучения

В этом уроке мы узнаем, что такое проектирование запросов, почему оно важно и как создавать более эффективные запросы для конкретной модели и цели приложения. Мы разберем основные концепции и лучшие практики проектирования запросов, а также познакомимся с интерактивной средой "песочницы" Jupyter Notebooks, где можно увидеть применение этих концепций на реальных примерах.

К концу урока мы сможем:

1. Объяснить, что такое проектирование запросов и почему оно важно.
2. Описать компоненты запроса и их использование.
3. Изучить лучшие практики и техники проектирования запросов.
4. Применить изученные техники на реальных примерах, используя конечную точку OpenAI.

## Ключевые термины

Проектирование запросов: Практика разработки и уточнения входных данных для направляющего воздействия на модели ИИ с целью получения желаемых результатов.
Токенизация: Процесс преобразования текста в меньшие единицы, называемые токенами, которые модель может понять и обработать.
LLM, настроенные на инструкции: Большие языковые модели (LLM), которые были доработаны с использованием конкретных инструкций для повышения точности и релевантности ответов.

## Песочница для обучения

Проектирование запросов на данный момент больше похоже на искусство, чем на науку. Лучший способ улучшить интуицию в этой области — это _практиковаться больше_ и использовать подход проб и ошибок, который сочетает экспертные знания в области приложения с рекомендованными техниками и оптимизациями, специфичными для модели.

Jupyter Notebook, сопровождающий этот урок, предоставляет _песочницу_, где вы можете пробовать изученные концепции — по ходу урока или в рамках задания в конце. Для выполнения упражнений вам потребуется:

1. **Ключ API Azure OpenAI** — конечная точка сервиса для развернутой LLM.
2. **Среда выполнения Python** — для выполнения Notebook.
3. **Локальные переменные окружения** — _выполните шаги [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), чтобы подготовиться_.

Notebook содержит _начальные_ упражнения, но вам предлагается добавлять свои собственные _Markdown_ (описания) и _Code_ (запросы) секции, чтобы попробовать больше примеров или идей и развить интуицию в проектировании запросов.

## Иллюстрированное руководство

Хотите получить общее представление о том, что охватывает этот урок, перед тем как углубиться? Ознакомьтесь с этим иллюстрированным руководством, которое дает представление о главных темах урока и ключевых выводах, над которыми стоит задуматься. Дорожная карта урока проведет вас от понимания основных концепций и вызовов к их решению с помощью соответствующих техник проектирования запросов и лучших практик. Обратите внимание, что раздел "Продвинутые техники" в этом руководстве относится к содержанию, охватываемому в _следующей_ главе этой программы.

![Иллюстрированное руководство по проектированию запросов](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.ru.png)

## Наша стартап-идея

Теперь давайте поговорим о том, как _эта тема_ связана с нашей миссией стартапа [привнести инновации ИИ в образование](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Мы хотим создавать приложения с поддержкой ИИ для _персонализированного обучения_, поэтому давайте подумаем, как разные пользователи нашего приложения могут "разрабатывать" запросы:

- **Администраторы** могут попросить ИИ _проанализировать данные учебных программ для выявления пробелов в охвате_. ИИ может суммировать результаты или визуализировать их с помощью кода.
- **Преподаватели** могут попросить ИИ _создать план урока для целевой аудитории и темы_. ИИ может составить персонализированный план в заданном формате.
- **Студенты** могут попросить ИИ _помочь им в сложной теме_. ИИ может направлять студентов с уроками, подсказками и примерами, адаптированными к их уровню.

И это только верхушка айсберга. Ознакомьтесь с [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) — библиотекой открытых запросов, созданной экспертами в области образования, чтобы получить более широкое представление о возможностях! _Попробуйте запустить некоторые из этих запросов в песочнице или в OpenAI Playground, чтобы увидеть, что получится!_

<!--
Шаблон урока:
Этот раздел должен охватывать основную концепцию #1.
Укрепите концепцию примерами и ссылками.

КОНЦЕПЦИЯ #1:
Проектирование запросов.
Определите его и объясните, почему оно необходимо.
-->

## Что такое проектирование запросов?

Мы начали этот урок с определения **Проектирования запросов** как процесса _разработки и оптимизации_ текстовых входных данных (запросов) для обеспечения стабильных и качественных ответов (завершений) для конкретной цели приложения и модели. Мы можем рассматривать это как процесс из двух шагов:

- _разработка_ начального запроса для конкретной модели и цели
- _уточнение_ запроса итеративно для улучшения качества ответа

Это обязательно процесс проб и ошибок, который требует интуиции и усилий пользователя для достижения оптимальных результатов. Так почему это важно? Чтобы ответить на этот вопрос, сначала нужно понять три концепции:

- _Токенизация_ = как модель "видит" запрос
- _Базовые LLM_ = как базовая модель "обрабатывает" запрос
- _LLM, настроенные на инструкции_ = как модель теперь видит "задачи"

### Токенизация

LLM видит запросы как _последовательность токенов_, где разные модели (или версии модели) могут токенизировать один и тот же запрос по-разному. Поскольку LLM обучаются на токенах (а не на необработанном тексте), способ токенизации запросов напрямую влияет на качество генерируемого ответа.

Чтобы получить интуитивное представление о том, как работает токенизация, попробуйте инструменты, такие как [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst), показанный ниже. Скопируйте свой запрос — и посмотрите, как он преобразуется в токены, обращая внимание на то, как обрабатываются пробелы и знаки препинания. Обратите внимание, что этот пример показывает более старую LLM (GPT-3) — поэтому использование более новой модели может дать другой результат.

![Токенизация](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.ru.png)

### Концепция: Базовые модели

После токенизации запроса основная функция ["Базовой LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (или базовой модели) заключается в предсказании следующего токена в этой последовательности. Поскольку LLM обучены на огромных текстовых наборах данных, они хорошо понимают статистические связи между токенами и могут делать предсказания с определенной уверенностью. Обратите внимание, что они не понимают _значение_ слов в запросе или токене; они просто видят шаблон, который могут "завершить" своим следующим предсказанием. Они могут продолжать предсказывать последовательность до тех пор, пока пользователь не прервет процесс или не будет достигнуто заранее установленное условие.

Хотите увидеть, как работает завершение на основе запросов? Введите вышеуказанный запрос в [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) Azure OpenAI Studio с настройками по умолчанию. Система настроена на обработку запросов как запросов информации — поэтому вы должны увидеть завершение, которое удовлетворяет этому контексту.

Но что, если пользователь хотел бы увидеть что-то конкретное, соответствующее определенным критериям или цели задачи? Здесь на помощь приходят _LLM, настроенные на инструкции_.

![Завершение чата базовой LLM](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.ru.png)

### Концепция: LLM, настроенные на инструкции

[LLM, настроенные на инструкции](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) начинаются с базовой модели и дорабатываются с помощью примеров или пар входных/выходных данных (например, многократных "сообщений"), которые могут содержать четкие инструкции — и ответ ИИ пытается следовать этим инструкциям.

Это использует такие техники, как обучение с подкреплением на основе обратной связи от человека (RLHF), которые позволяют модели _следовать инструкциям_ и _учиться на обратной связи_, чтобы она генерировала ответы, лучше подходящие для практических приложений и более релевантные целям пользователя.

Давайте попробуем — вернитесь к вышеуказанному запросу, но теперь измените _системное сообщение_, чтобы предоставить следующую инструкцию как контекст:

> _Суммируйте предоставленный контент для ученика второго класса. Сохраните результат в одном абзаце с 3-5 пунктами._

Посмотрите, как результат теперь настроен для отражения желаемой цели и формата? Преподаватель теперь может напрямую использовать этот ответ в своих слайдах для урока.

![Завершение чата LLM, настроенной на инструкции](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.ru.png)

## Зачем нужно проектирование запросов?

Теперь, когда мы знаем, как запросы обрабатываются LLM, давайте поговорим о _почему_ нам нужно проектирование запросов. Ответ заключается в том, что текущие LLM имеют ряд вызовов, которые делают _надежные и стабильные завершения_ более сложными для достижения без усилий по созданию и оптимизации запросов. Например:

1. **Ответы модели являются стохастическими.** _Один и тот же запрос_ может давать разные ответы с разными моделями или версиями модели. И он может даже давать разные результаты с _той же моделью_ в разное время. _Техники проектирования запросов могут помочь минимизировать эти вариации, предоставляя лучшие рамки_.

1. **Модели могут фабриковать ответы.** Модели предварительно обучены на _больших, но конечных_ наборах данных, что означает, что они не знают концепций за пределами этого объема обучения. В результате они могут генерировать завершения, которые являются неточными, вымышленными или прямо противоречат известным фактам. _Техники проектирования запросов помогают пользователям выявлять и устранять такие фабрикации, например, запрашивая у ИИ ссылки или рассуждения_.

1. **Возможности моделей будут различаться.** Новые модели или поколения моделей будут иметь более богатые возможности, но также принесут уникальные особенности и компромиссы в стоимости и сложности. _Проектирование запросов может помочь разработать лучшие практики и рабочие процессы, которые абстрагируют различия и адаптируются к требованиям конкретных моделей масштабируемым и бесшовным образом_.

Давайте посмотрим это в действии в OpenAI или Azure OpenAI Playground:

- Используйте один и тот же запрос с разными развертываниями LLM (например, OpenAI, Azure OpenAI, Hugging Face) — заметили ли вы различия?
- Используйте один и тот же запрос несколько раз с _одним и тем же_ развертыванием LLM (например, Azure OpenAI Playground) — как эти вариации отличались?

### Пример фабрикаций

В этом курсе мы используем термин **"фабрикация"** для обозначения явления, когда LLM иногда генерируют фактически некорректную информацию из-за ограничений их обучения или других факторов. Вы могли также слышать, как это называют _"галлюцинациями"_ в популярных статьях или научных работах. Однако мы настоятельно рекомендуем использовать термин _"фабрикация"_, чтобы случайно не приписывать человеческие черты машинному поведению. Это также соответствует [Руководству по ответственному ИИ](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) с точки зрения терминологии, исключая термины, которые могут быть сочтены оскорбительными или неинклюзивными в некоторых контекстах.

Хотите понять, как работают фабрикации? Придумайте запрос, который инструктирует ИИ создать контент для несуществующей темы (чтобы убедиться, что она не найдена в наборе данных обучения). Например, я попробовал этот запрос:

> **Запрос:** создайте план урока о Марсианской войне 2076 года.
Веб-поиск показал, что существуют вымышленные произведения (например, телесериалы или книги) о марсианских войнах, но ни одно из них не связано с 2076 годом. Здравый смысл также подсказывает, что 2076 год — это _будущее_, и, следовательно, не может быть связан с реальным событием.

Что же произойдет, если мы запустим этот запрос с различными поставщиками LLM?

> **Ответ 1**: OpenAI Playground (GPT-35)

![Ответ 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.ru.png)

> **Ответ 2**: Azure OpenAI Playground (GPT-35)

![Ответ 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.ru.png)

> **Ответ 3**: Hugging Face Chat Playground (LLama-2)

![Ответ 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.ru.png)

Как и ожидалось, каждая модель (или версия модели) генерирует немного разные ответы благодаря стохастическому поведению и различиям в возможностях моделей. Например, одна модель ориентируется на аудиторию восьмого класса, а другая предполагает уровень старшеклассника. Однако все три модели создали ответы, которые могли бы убедить неинформированного пользователя, что событие реально.

Техники проектирования запросов, такие как _метапромптинг_ и _настройка температуры_, могут в некоторой степени уменьшить фабрикации моделей. Новые архитектуры проектирования запросов также интегрируют новые инструменты и методы в поток запросов, чтобы смягчить или уменьшить некоторые из этих эффектов.

## Пример: GitHub Copilot

Завершим этот раздел, рассмотрев, как проектирование запросов используется в реальных решениях, на примере [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot — это ваш "AI-помощник программиста", который преобразует текстовые запросы в завершения кода и интегрируется в вашу среду разработки (например, Visual Studio Code) для удобного использования. Как описано в серии блогов ниже, самая ранняя версия была основана на модели OpenAI Codex — инженеры быстро поняли необходимость доработки модели и разработки более эффективных техник проектирования запросов для улучшения качества кода. В июле они [представили улучшенную AI-модель, которая превосходит Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) для еще более быстрых предложений.

Читайте посты по порядку, чтобы проследить их путь обучения.

- **Май 2023** | [GitHub Copilot становится лучше в понимании вашего кода](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Май 2023** | [Внутри GitHub: Работа с LLM, стоящими за GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Июнь 2023** | [Как писать лучшие запросы для GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Июль 2023** | [GitHub Copilot выходит за рамки Codex с улучшенной AI-моделью](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Июль 2023** | [Руководство разработчика по проектированию запросов и LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Сентябрь 2023** | [Как создать корпоративное приложение на основе LLM: уроки от GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Вы также можете просмотреть их [инженерный блог](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) для других постов, таких как [этот](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), который показывает, как эти модели и техники _применяются_ для создания реальных приложений.

---

## Конструкция запросов

Мы уже видели, почему проектирование запросов важно — теперь давайте разберемся, как запросы _конструируются_, чтобы мы могли оценить различные техники для более эффективного проектирования запросов.

### Базовый запрос

Начнем с базового запроса: текстовый ввод, отправляемый модели без дополнительного контекста. Вот пример — когда мы отправляем первые слова национального гимна США в OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), он мгновенно _дополняет_ ответ следующими строками, демонстрируя базовое поведение предсказания.

| Запрос (ввод)     | Завершение (вывод)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Похоже, вы начинаете текст "The Star-Spangled Banner", национального гимна США. Полный текст выглядит следующим образом... |

### Сложный запрос

Теперь добавим контекст и инструкции к базовому запросу. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) позволяет нам конструировать сложный запрос как коллекцию _сообщений_ с:

- Парами ввода/вывода, отражающими _ввод пользователя_ и _ответ помощника_.
- Системным сообщением, задающим контекст для поведения или личности помощника.

Запрос теперь выглядит следующим образом, где _токенизация_ эффективно захватывает релевантную информацию из контекста и беседы. Теперь изменение системного контекста может быть столь же значимым для качества завершений, как и предоставленные пользователем вводы.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```


### Инструктивный запрос

В приведенных выше примерах запрос пользователя был простым текстовым запросом, который можно интерпретировать как запрос информации. С _инструктивными_ запросами мы можем использовать этот текст для более детального указания задачи, предоставляя более четкие рекомендации для AI. Вот пример:

| Запрос (ввод)                                                                                                                                                                                                                         | Завершение (вывод)                                                                                                        | Тип инструкции      |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Напишите описание Гражданской войны                                                                                                                                                                                                   | _возвращен простой абзац_                                                                                                 | Простой             |
| Напишите описание Гражданской войны. Укажите ключевые даты и события и опишите их значение                                                                                                                                           | _возвращен абзац, за которым следует список ключевых дат событий с описаниями_                                            | Сложный             |
| Напишите описание Гражданской войны в 1 абзаце. Укажите 3 ключевые даты и их значение в виде маркеров. Укажите еще 3 ключевые исторические фигуры и их вклад в виде маркеров. Верните вывод в формате JSON-файла                       | _возвращены более подробные данные в текстовом поле, отформатированном как JSON, который можно скопировать и проверить_   | Сложный. Форматированный. |

## Основной контент

В приведенных выше примерах запрос был довольно открытым, позволяя LLM решать, какая часть его предварительно обученного набора данных была релевантной. С шаблоном _основного контента_ входной текст делится на две части:

- инструкция (действие)
- релевантный контент (влияющий на действие)

Вот пример, где инструкция — "суммируйте это в 2 предложениях".

| Запрос (ввод)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Завершение (вывод)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Юпитер — пятая планета от Солнца и самая большая в Солнечной системе. Это газовый гигант с массой, составляющей одну тысячную от массы Солнца, но в два с половиной раза больше массы всех остальных планет Солнечной системы вместе взятых. Юпитер — один из самых ярких объектов, видимых невооруженным глазом в ночном небе, и известен древним цивилизациям с доисторических времен. Он назван в честь римского бога Юпитера. Когда Юпитер виден с Земли, его отраженный свет может быть достаточно ярким, чтобы отбрасывать видимые тени, и в среднем он является третьим по яркости естественным объектом в ночном небе после Луны и Венеры. <br/> **Суммируйте это в 2 коротких предложениях** | Юпитер, пятая планета от Солнца, является самой большой в Солнечной системе и известен как один из самых ярких объектов в ночном небе. Названный в честь римского бога Юпитера, это газовый гигант, масса которого в два с половиной раза больше массы всех остальных планет вместе взятых. |

Сегмент основного контента может использоваться различными способами для более эффективных инструкций:

- **Примеры** — вместо того, чтобы явно говорить модели, что делать, предоставьте ей примеры желаемого результата и позвольте ей вывести шаблон.
- **Подсказки** — следуйте инструкции с "подсказкой", которая направляет завершение, помогая модели генерировать более релевантные ответы.
- **Шаблоны** — это повторяемые "рецепты" для запросов с заполнителями (переменными), которые можно настроить данными для конкретных случаев использования.

Давайте рассмотрим эти подходы в действии.

### Использование примеров

Это подход, при котором вы используете основной контент, чтобы "накормить модель" примерами желаемого результата для данной инструкции, и позволяете ей вывести шаблон для желаемого результата. В зависимости от количества предоставленных примеров, мы можем иметь запросы без примеров (zero-shot), с одним примером (one-shot), с несколькими примерами (few-shot) и т.д.

Запрос теперь состоит из трех компонентов:

- Описание задачи
- Несколько примеров желаемого результата
- Начало нового примера (которое становится неявным описанием задачи)

| Тип обучения | Запрос (ввод)                                                                                                                                        | Завершение (вывод)         |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot    | "Солнце светит". Переведите на испанский                                                                                                             | "El Sol está brillando".    |
| One-shot     | "Солнце светит" => ""El Sol está brillando". <br> "Сегодня холодный и ветреный день" =>                                                              | "Es un día frío y ventoso". |
| Few-shot     | Игрок пробежал базы => Бейсбол <br/> Игрок сделал эйс => Теннис <br/> Игрок выбил шестерку => Крикет <br/> Игрок сделал слэм-данк =>                 | Баскетбол                  |
|              |                                                                                                                                                       |                             |

Обратите внимание, что в запросе без примеров (zero-shot) мы должны были явно указать инструкцию ("Переведите на испанский"), но она выводится в запросе с одним примером (one-shot). Пример с несколькими примерами (few-shot) показывает, как добавление большего количества примеров позволяет моделям делать более точные выводы без дополнительных инструкций.

### Подсказки в запросах

Еще одна техника использования основного контента — предоставление _подсказок_, а не примеров. В этом случае мы даем модели намек в нужном направлении, _начиная_ с фрагмента, который отражает желаемый формат ответа. Модель затем "берет подсказку" и продолжает в том же духе.

| Количество подсказок | Запрос (ввод)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Завершение (вывод)                                                                                                                                                                                                                                                                                       |
| :------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                   | Юпитер — пятая планета от Солнца и самая большая в Солнечной системе. Это газовый гигант с массой, составляющей одну тысячную от массы Солнца, но в два с половиной раза больше массы всех остальных планет Солнечной системы вместе взятых. Юпитер — один из самых ярких объектов, видимых невооруженным глазом в ночном небе, и известен древним цивилизациям с доисторических времен. <br/>**Суммируйте это**                                       | Юпитер — самая большая планета в нашей Солнечной системе и пятая от Солнца. Это газовый гигант с массой, составляющей 1/1000 массы Солнца, но он тяжелее всех остальных планет вместе взятых. Древние цивилизации давно знали о Юпитере, и он легко виден в ночном небе. |
| 1              | Юпитер — пятая планета от Солнца и самая большая в Солнечной системе. Это газовый гигант с массой, составляющей одну тысячную от массы Солнца, но в два с половиной раза больше массы всех остальных планет Солнечной системы вместе взятых. Юпитер — один из самых ярких объектов, видимых невооруженным глазом в ночном небе, и был известен древним цивилизациям еще до начала письменной истории. <br/>**Краткий вывод** <br/> Мы узнали, что Юпитер | является пятой планетой от Солнца и самой большой в Солнечной системе. Это газовый гигант с массой, составляющей одну тысячную от массы Солнца, но в два с половиной раза больше массы всех остальных планет вместе взятых. Он легко виден невооруженным глазом и был известен с древних времен.                        |
| 2              | Юпитер — пятая планета от Солнца и самая большая в Солнечной системе. Это газовый гигант с массой, составляющей одну тысячную от массы Солнца, но в два с половиной раза больше массы всех остальных планет Солнечной системы вместе взятых. Юпитер — один из самых ярких объектов, видимых невооруженным глазом в ночном небе, и был известен древним цивилизациям еще до начала письменной истории. <br/>**Краткий вывод** <br/> Топ-3 факта, которые мы узнали:         | 1. Юпитер — пятая планета от Солнца и самая большая в Солнечной системе. <br/> 2. Это газовый гигант с массой, составляющей одну тысячную от массы Солнца...<br/> 3. Юпитер был виден невооруженным глазом с древних времен ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Шаблоны подсказок

Шаблон подсказки — это _предопределенный рецепт для подсказки_, который можно сохранить и использовать повторно по мере необходимости, чтобы обеспечить более последовательный пользовательский опыт в масштабах. В своей самой простой форме это просто коллекция примеров подсказок, как [этот от OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), который предоставляет как интерактивные компоненты подсказки (сообщения пользователя и системы), так и формат запроса через API — для поддержки повторного использования.

В более сложной форме, как [этот пример от LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), он содержит _заполнители_, которые могут быть заменены данными из различных источников (ввод пользователя, контекст системы, внешние источники данных и т. д.) для динамического создания подсказки. Это позволяет создать библиотеку повторно используемых подсказок, которые можно использовать для обеспечения последовательного пользовательского опыта **программно** в масштабах.

Наконец, настоящая ценность шаблонов заключается в возможности создавать и публиковать _библиотеки подсказок_ для вертикальных областей применения, где шаблон подсказки теперь _оптимизирован_ для отражения контекста или примеров, специфичных для приложения, что делает ответы более релевантными и точными для целевой аудитории пользователей. Репозиторий [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) — отличный пример такого подхода, который курирует библиотеку подсказок для образовательной области с акцентом на ключевые цели, такие как планирование уроков, разработка учебных программ, репетиторство студентов и т. д.

## Дополнительный контент

Если рассматривать создание подсказок как процесс, включающий инструкцию (задачу) и цель (основной контент), то _вторичный контент_ — это дополнительный контекст, который мы предоставляем, чтобы **влиять на результат каким-либо образом**. Это могут быть параметры настройки, инструкции по форматированию, таксономии тем и т. д., которые помогают модели _адаптировать_ свой ответ для достижения желаемых целей или ожиданий пользователя.

Например: Имея каталог курсов с обширными метаданными (название, описание, уровень, метки, преподаватель и т. д.) обо всех доступных курсах в учебной программе:

- мы можем определить инструкцию: "составьте краткое описание каталога курсов на осень 2023 года"
- мы можем использовать основной контент, чтобы предоставить несколько примеров желаемого результата
- мы можем использовать вторичный контент, чтобы выделить 5 "меток", представляющих интерес.

Теперь модель может предоставить краткое описание в формате, показанном в нескольких примерах, но если результат имеет несколько меток, она может приоритизировать 5 меток, указанных во вторичном контенте.

---

<!--
ШАБЛОН УРОКА:
Этот раздел должен охватывать ключевую концепцию №1.
Укрепите концепцию примерами и ссылками.

КОНЦЕПЦИЯ №3:
Техники инженерии подсказок.
Какие основные техники существуют для инженерии подсказок?
Иллюстрируйте их упражнениями.
-->

## Лучшие практики создания подсказок

Теперь, когда мы знаем, как подсказки могут быть _составлены_, мы можем начать думать о том, как их _разрабатывать_, чтобы они отражали лучшие практики. Мы можем рассматривать это в двух частях — правильный _подход_ и применение правильных _техник_.

### Подход к инженерии подсказок

Инженерия подсказок — это процесс проб и ошибок, поэтому держите в уме три широких руководящих принципа:

1. **Понимание области имеет значение.** Точность и релевантность ответа зависят от _области_, в которой работает приложение или пользователь. Используйте свою интуицию и экспертные знания в области, чтобы **дополнительно настроить техники**. Например, определите _персональности, специфичные для области_ в системных подсказках или используйте _шаблоны, специфичные для области_ в пользовательских подсказках. Предоставьте вторичный контент, который отражает контексты, специфичные для области, или используйте _подсказки и примеры, специфичные для области_, чтобы направить модель к знакомым шаблонам использования.

2. **Понимание модели имеет значение.** Мы знаем, что модели по своей природе являются стохастическими. Но реализации моделей также могут различаться в зависимости от используемого набора данных для обучения (предварительно обученные знания), предоставляемых возможностей (например, через API или SDK) и типа контента, для которого они оптимизированы (например, код, изображения или текст). Поймите сильные и слабые стороны модели, которую вы используете, и используйте эти знания, чтобы _приоритизировать задачи_ или создавать _настроенные шаблоны_, оптимизированные для возможностей модели.

3. **Итерация и проверка имеют значение.** Модели быстро развиваются, как и техники инженерии подсказок. Как эксперт в области, вы можете иметь другой контекст или критерии для _вашего_ конкретного приложения, которые могут не применяться к более широкой аудитории. Используйте инструменты и техники инженерии подсказок, чтобы "запустить" процесс создания подсказок, затем итеративно проверяйте результаты, используя свою интуицию и экспертные знания в области. Записывайте свои наблюдения и создавайте **базу знаний** (например, библиотеки подсказок), которые могут быть использованы как новая отправная точка для других, чтобы ускорить итерации в будущем.

## Лучшие практики

Теперь давайте рассмотрим общие лучшие практики, рекомендованные специалистами [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) и [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Что                              | Почему                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Оцените последние модели.       | Новые поколения моделей, вероятно, имеют улучшенные функции и качество, но могут также быть более дорогими. Оцените их влияние, затем принимайте решения о миграции.                                                                                |
| Разделяйте инструкции и контекст   | Проверьте, определяет ли ваша модель/поставщик _разделители_, чтобы более четко различать инструкции, основной и вторичный контент. Это может помочь моделям более точно назначать веса токенам.                                                         |
| Будьте конкретными и ясными             | Дайте больше деталей о желаемом контексте, результате, длине, формате, стиле и т. д. Это улучшит как качество, так и последовательность ответов. Сохраняйте рецепты в повторно используемых шаблонах.                                                          |
| Будьте описательными, используйте примеры      | Модели могут лучше реагировать на подход "покажи и расскажи". Начните с подхода `zero-shot`, где вы даете инструкцию (но без примеров), затем попробуйте `few-shot` как уточнение, предоставляя несколько примеров желаемого результата. Используйте аналогии. |
| Используйте подсказки для запуска завершений | Направьте модель к желаемому результату, предоставив ей несколько начальных слов или фраз, которые она может использовать как отправную точку для ответа.                                                                                                               |
| Повторяйте                       | Иногда вам может понадобиться повторить инструкции модели. Дайте инструкции до и после основного контента, используйте инструкцию и подсказку и т. д. Итеративно проверяйте, что работает.                                                         |
| Порядок имеет значение                     | Порядок, в котором вы представляете информацию модели, может влиять на результат, даже в примерах обучения, благодаря эффекту недавности. Попробуйте разные варианты, чтобы увидеть, что работает лучше.                                                               |
| Дайте модели "выход"           | Предоставьте модели _резервный_ ответ, который она может дать, если не сможет выполнить задачу по какой-либо причине. Это может снизить вероятность генерации ложных или вымышленных ответов.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Как и в случае с любыми лучшими практиками, помните, что _ваш опыт может отличаться_ в зависимости от модели, задачи и области. Используйте их как отправную точку и итеративно находите то, что работает лучше всего для вас. Постоянно переоценивайте процесс инженерии подсказок по мере появления новых моделей и инструментов, с акцентом на масштабируемость процесса и качество ответов.

<!--
ШАБЛОН УРОКА:
Этот раздел должен предоставить задачу с кодом, если применимо.

ЗАДАЧА:
Ссылка на Jupyter Notebook с только комментариями кода в инструкциях (разделы кода пусты).

РЕШЕНИЕ:
Ссылка на копию этого Notebook с заполненными и выполненными подсказками, показывающая, каким может быть один пример.
-->

## Задание

Поздравляем! Вы дошли до конца урока! Теперь пришло время проверить некоторые из этих концепций и техник на практике с реальными примерами!

Для выполнения задания мы будем использовать Jupyter Notebook с упражнениями, которые вы можете выполнить интерактивно. Вы также можете расширить Notebook своими собственными ячейками Markdown и Code, чтобы исследовать идеи и техники самостоятельно.

### Чтобы начать, сделайте форк репозитория, затем

- (Рекомендуется) Запустите GitHub Codespaces
- (Альтернативно) Клонируйте репозиторий на свое устройство и используйте его с Docker Desktop
- (Альтернативно) Откройте Notebook в предпочитаемой среде выполнения Notebook.

### Далее, настройте переменные окружения

- Скопируйте файл `.env.copy` в корне репозитория в `.env` и заполните значения `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` и `AZURE_OPENAI_DEPLOYMENT`. Вернитесь к разделу [Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), чтобы узнать, как это сделать.

### Затем откройте Jupyter Notebook

- Выберите ядро выполнения. Если вы используете варианты 1 или 2, просто выберите ядро Python 3.10.x, предоставленное контейнером разработки.

Вы готовы выполнять упражнения. Обратите внимание, что здесь нет _правильных и неправильных_ ответов — просто исследуйте варианты методом проб и ошибок и развивайте интуицию о том, что работает для данной модели и области применения.

_По этой причине в этом уроке нет сегментов с решениями кода. Вместо этого в Notebook будут ячейки Markdown с заголовком "Мое решение:", которые показывают один пример результата для справки._

 <!--
ШАБЛОН УРОКА:
Заключите раздел кратким итогом и ресурсами для самостоятельного обучения.
-->

## Проверка знаний

Какой из следующих вариантов является хорошей подсказкой, следуя разумным лучшим практикам?

1. Покажи мне изображение красной машины
2. Покажи мне изображение красной машины марки Volvo и модели XC90, припаркованной у обрыва на фоне заката
3. Покажи мне изображение красной машины марки Volvo и модели XC90

A: 2, это лучшая подсказка, так как она предоставляет детали о "чем" и идет в конкретику (не просто любая машина, а определенная марка и модель), а также описывает общий антураж. 3 — следующий лучший вариант, так как он также содержит много описания.

## 🚀 Задача

Попробуйте использовать технику "подсказки" с запросом: Завершите предложение "Покажи мне изображение красной машины марки Volvo и ". Что модель ответит, и как вы бы улучшили это?

## Отличная работа! Продолжайте обучение

Хотите узнать больше о различных концепциях инженерии подсказок? Перейдите на [страницу продолжения обучения](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), чтобы найти другие отличные ресурсы по этой теме.

Перейдите к уроку 5, где мы рассмотрим [продвинутые техники создания подсказок](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.